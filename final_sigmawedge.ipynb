{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e73229-094b-4e29-b249-8e0cdd6d0c29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'licensekey': 'bceb........d2f3', 'software_license': {}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quantrocket.license import get_license_profile\n",
    "get_license_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1686b2dc-8805-4426-97b9-64c380cf88ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from quantrocket.history import create_usstock_db, collect_history\n",
    "from quantrocket.master import get_securities\n",
    "from quantrocket.history import download_history_file\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "841c450c-8c3a-4157-92a6-45d0195860ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'licensekey': 'bceb........d2f3', 'software_license': {}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quantrocket.license import set_license\n",
    "set_license(\"bceb5580-e38b-11ee-bc17-c19b940fd2f3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a7ee9fb-4e5a-4ca1-8b3b-19796a39e4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'deleted quantrocket.v2.history.usstock-free-1d.sqlite'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quantrocket.history import drop_db\n",
    "drop_db(\"usstock-free-1d\", confirm_by_typing_db_code_again=\"usstock-free-1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a5a21a2-bdfc-4133-a427-2f5633d58c88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'successfully created quantrocket.v2.history.usstock-free-1d.sqlite'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quantrocket.history import create_usstock_db\n",
    "create_usstock_db(\"usstock-free-1d\", bar_size=\"1 day\", free=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c19a1403-4672-473a-9a88-a2a12469de09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'the historical data will be collected asynchronously'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quantrocket.history import collect_history\n",
    "collect_history(\"usstock-free-1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b5ccc5d-3658-485f-9730-f29d6940cdf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Country</th>\n",
       "      <th>Currency</th>\n",
       "      <th>SecType</th>\n",
       "      <th>Etf</th>\n",
       "      <th>Timezone</th>\n",
       "      <th>Name</th>\n",
       "      <th>PriceMagnifier</th>\n",
       "      <th>Multiplier</th>\n",
       "      <th>Delisted</th>\n",
       "      <th>DateDelisted</th>\n",
       "      <th>LastTradeDate</th>\n",
       "      <th>RolloverDate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FIBBG000B9XRY4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>XNAS</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>STK</td>\n",
       "      <td>False</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>APPLE INC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIBBG000BFWKC0</th>\n",
       "      <td>MON</td>\n",
       "      <td>XNYS</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>STK</td>\n",
       "      <td>False</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>MONSANTO CO</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIBBG000BKZB36</th>\n",
       "      <td>HD</td>\n",
       "      <td>XNYS</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>STK</td>\n",
       "      <td>False</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>HOME DEPOT INC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIBBG000BMHYD1</th>\n",
       "      <td>JNJ</td>\n",
       "      <td>XNYS</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>STK</td>\n",
       "      <td>False</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>JOHNSON &amp; JOHNSON</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIBBG000BPH459</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>XNAS</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>STK</td>\n",
       "      <td>False</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>MICROSOFT CORP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIBBG000CK38G3</th>\n",
       "      <td>KKD</td>\n",
       "      <td>XNYS</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>STK</td>\n",
       "      <td>False</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>KRISPY KREME DOUGHNUTS INC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIBBG000GZQ728</th>\n",
       "      <td>XOM</td>\n",
       "      <td>XNYS</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>STK</td>\n",
       "      <td>False</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>EXXON MOBIL CORP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIBBG00B3T3HD3</th>\n",
       "      <td>AA</td>\n",
       "      <td>XNYS</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>STK</td>\n",
       "      <td>False</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>ALCOA CORP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Symbol Exchange Country Currency SecType    Etf  \\\n",
       "Sid                                                              \n",
       "FIBBG000B9XRY4   AAPL     XNAS      US      USD     STK  False   \n",
       "FIBBG000BFWKC0    MON     XNYS      US      USD     STK  False   \n",
       "FIBBG000BKZB36     HD     XNYS      US      USD     STK  False   \n",
       "FIBBG000BMHYD1    JNJ     XNYS      US      USD     STK  False   \n",
       "FIBBG000BPH459   MSFT     XNAS      US      USD     STK  False   \n",
       "FIBBG000CK38G3    KKD     XNYS      US      USD     STK  False   \n",
       "FIBBG000GZQ728    XOM     XNYS      US      USD     STK  False   \n",
       "FIBBG00B3T3HD3     AA     XNYS      US      USD     STK  False   \n",
       "\n",
       "                        Timezone                        Name  PriceMagnifier  \\\n",
       "Sid                                                                            \n",
       "FIBBG000B9XRY4  America/New_York                   APPLE INC               1   \n",
       "FIBBG000BFWKC0  America/New_York                 MONSANTO CO               1   \n",
       "FIBBG000BKZB36  America/New_York              HOME DEPOT INC               1   \n",
       "FIBBG000BMHYD1  America/New_York           JOHNSON & JOHNSON               1   \n",
       "FIBBG000BPH459  America/New_York              MICROSOFT CORP               1   \n",
       "FIBBG000CK38G3  America/New_York  KRISPY KREME DOUGHNUTS INC               1   \n",
       "FIBBG000GZQ728  America/New_York            EXXON MOBIL CORP               1   \n",
       "FIBBG00B3T3HD3  America/New_York                  ALCOA CORP               1   \n",
       "\n",
       "                Multiplier  Delisted DateDelisted LastTradeDate RolloverDate  \n",
       "Sid                                                                           \n",
       "FIBBG000B9XRY4           1     False          NaT           NaT          NaT  \n",
       "FIBBG000BFWKC0           1      True   2018-06-06           NaT          NaT  \n",
       "FIBBG000BKZB36           1     False          NaT           NaT          NaT  \n",
       "FIBBG000BMHYD1           1     False          NaT           NaT          NaT  \n",
       "FIBBG000BPH459           1     False          NaT           NaT          NaT  \n",
       "FIBBG000CK38G3           1      True   2016-07-27           NaT          NaT  \n",
       "FIBBG000GZQ728           1     False          NaT           NaT          NaT  \n",
       "FIBBG00B3T3HD3           1     False          NaT           NaT          NaT  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quantrocket.master import get_securities\n",
    "securities = get_securities(vendors=\"usstock\", sec_types=\"STK\")\n",
    "securities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b13a03-7a7f-4198-891d-e85c31278e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantrocket.master import create_universe\n",
    "create_universe(\"usstockfrees\", sids=securities.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ea1f08b-fcd6-4443-83bd-bc4599e2b4e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_securities = securities[securities.Delisted==False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e55299bd-6548-49e5-9de3-8291f32ab492",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Name</th>\n",
       "      <th>Delisted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FIBBG000B9XRY4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>XNAS</td>\n",
       "      <td>APPLE INC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIBBG000BKZB36</th>\n",
       "      <td>HD</td>\n",
       "      <td>XNYS</td>\n",
       "      <td>HOME DEPOT INC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIBBG000BMHYD1</th>\n",
       "      <td>JNJ</td>\n",
       "      <td>XNYS</td>\n",
       "      <td>JOHNSON &amp; JOHNSON</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIBBG000BPH459</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>XNAS</td>\n",
       "      <td>MICROSOFT CORP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIBBG000GZQ728</th>\n",
       "      <td>XOM</td>\n",
       "      <td>XNYS</td>\n",
       "      <td>EXXON MOBIL CORP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIBBG00B3T3HD3</th>\n",
       "      <td>AA</td>\n",
       "      <td>XNYS</td>\n",
       "      <td>ALCOA CORP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Symbol Exchange               Name  Delisted\n",
       "Sid                                                        \n",
       "FIBBG000B9XRY4   AAPL     XNAS          APPLE INC     False\n",
       "FIBBG000BKZB36     HD     XNYS     HOME DEPOT INC     False\n",
       "FIBBG000BMHYD1    JNJ     XNYS  JOHNSON & JOHNSON     False\n",
       "FIBBG000BPH459   MSFT     XNAS     MICROSOFT CORP     False\n",
       "FIBBG000GZQ728    XOM     XNYS   EXXON MOBIL CORP     False\n",
       "FIBBG00B3T3HD3     AA     XNYS         ALCOA CORP     False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_securities = filtered_securities[[\"Symbol\", \"Exchange\", \"Name\", \"Delisted\"]]\n",
    "filtered_securities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4b572e9-5291-451b-b98d-98d2c4fd6734",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 'usstocks', 'provided': 6, 'inserted': 6, 'total_after_insert': 6}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_universe(\"usstocks\", sids=filtered_securities.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ed9d013-2c9d-4141-9d23-2902cb08f884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'successfully created quantrocket.v2.history.aapl.sqlite'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_usstock_db(\"aapl\", bar_size=\"1 day\", free=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54c3b3c2-8361-41c9-9f0d-0eceba3d5267",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'the historical data will be collected asynchronously'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_history(\"aapl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8393ec8a-761d-49af-9565-551cdf60c86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "securities = get_securities(vendors=\"usstock\", sec_types=\"STK\")\n",
    "aapl_sid = securities.loc[securities[\"Symbol\"] == \"AAPL\"].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f877a679-2030-4219-93c0-dec4774f92fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from quantrocket import get_prices\n",
    "price_data = get_prices(\"aapl\", sids=[\"FIBBG000B9XRY4\"], start_date=\"2022-01-01\", end_date=\"2022-12-31\", fields=[\"Close\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d86c3205-fbe1-47f3-a222-464682990b95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file_path = \"aapldata.csv\"\n",
    "price_data.to_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40e00ba9-7220-48c1-91b9-fe571e6c12a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 1)\n"
     ]
    }
   ],
   "source": [
    "print(price_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b74aad69-d9cb-43b2-b3a2-008d1a08d51e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sid               FIBBG000B9XRY4\n",
      "Field Date                      \n",
      "Close 2022-01-03        179.4980\n",
      "      2022-01-04        177.2199\n",
      "      2022-01-05        172.5058\n",
      "      2022-01-06        169.6261\n",
      "      2022-01-07        169.7938\n",
      "...                          ...\n",
      "      2022-12-23        130.9600\n",
      "      2022-12-27        129.1424\n",
      "      2022-12-28        125.1797\n",
      "      2022-12-29        128.7253\n",
      "      2022-12-30        129.0431\n",
      "\n",
      "[251 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(price_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18c5c586-b91f-4687-8950-797dea822b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      179.4980\n",
       "1      177.2199\n",
       "2      172.5058\n",
       "3      169.6261\n",
       "4      169.7938\n",
       "         ...   \n",
       "246    130.9600\n",
       "247    129.1424\n",
       "248    125.1797\n",
       "249    128.7253\n",
       "250    129.0431\n",
       "Name: Close, Length: 251, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prices = price_data['FIBBG000B9XRY4']['Close'].to_list()\n",
    "prices_df = pd.DataFrame({'Close': prices})\n",
    "prices_df['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edfe24a7-988e-498c-a302-4c00e6e8d9dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "returns_df = prices_df['Close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52659780-1e10-4e4b-9fa7-620f8c94a78b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           NaN\n",
      "1     -0.012692\n",
      "2     -0.026600\n",
      "3     -0.016693\n",
      "4      0.000989\n",
      "         ...   \n",
      "246   -0.001539\n",
      "247   -0.013879\n",
      "248   -0.030685\n",
      "249    0.028324\n",
      "250    0.002469\n",
      "Name: Close, Length: 251, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(returns_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1ad9a63-d4aa-4db1-a1d6-b8907703d2ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_returns(returns):\n",
    "    if returns > 0.01:\n",
    "        return 1\n",
    "    elif returns > -0.01:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6efd6c5-8fb3-4305-9662-ff4392a3f325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Close  Mapped_Returns\n",
      "0    179.4980              -1\n",
      "1    177.2199              -1\n",
      "2    172.5058              -1\n",
      "3    169.6261              -1\n",
      "4    169.7938               0\n",
      "..        ...             ...\n",
      "246  130.9600               0\n",
      "247  129.1424              -1\n",
      "248  125.1797              -1\n",
      "249  128.7253               1\n",
      "250  129.0431               0\n",
      "\n",
      "[251 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "mapped_returns = returns_df.apply(map_returns)\n",
    "\n",
    "prices_df['Mapped_Returns'] = mapped_returns\n",
    "\n",
    "print(prices_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43a2c8b5-e734-47fd-995a-89186f43ab44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transition_probabilities = np.array([[[0.0, 0.0, 0.0],\n",
    "                                      [0.4137931, 0.34482759, 0.24137931],\n",
    "                                      [0.0, 0.0, 0.0]],\n",
    "\n",
    "                                     [[1.0, 0.0, 0.0],\n",
    "                                      [0.0, 1.0, 0.0],\n",
    "                                      [0.0, 0.0, 1.0]],\n",
    "\n",
    "                                     [[0.0, 0.0, 0.0],\n",
    "                                      [0.28169014, 0.47887324, 0.23943662],\n",
    "                                      [0.0, 0.0, 0.0]]])\n",
    "\n",
    "\n",
    "# this is the transition probability matrix using our data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f72a3454-a186-4b31-b7d0-85544e9ab784",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bear': {'Buy': {'Bear': 0.3333333333333333, 'Bull': 0.3333333333333333, 'Flat': 0.3333333333333333}, 'Sell': {'Bear': 0.3333333333333333, 'Bull': 0.3333333333333333, 'Flat': 0.3333333333333333}, 'Hold': {'Bear': 0.3333333333333333, 'Bull': 0.3333333333333333, 'Flat': 0.3333333333333333}}, 'Bull': {'Buy': {'Bear': 0.3333333333333333, 'Bull': 0.3333333333333333, 'Flat': 0.3333333333333333}, 'Sell': {'Bear': 0.3333333333333333, 'Bull': 0.3333333333333333, 'Flat': 0.3333333333333333}, 'Hold': {'Bear': 0.3333333333333333, 'Bull': 0.3333333333333333, 'Flat': 0.3333333333333333}}, 'Flat': {'Buy': {'Bear': 0.3333333333333333, 'Bull': 0.3333333333333333, 'Flat': 0.3333333333333333}, 'Sell': {'Bear': 0.3333333333333333, 'Bull': 0.3333333333333333, 'Flat': 0.3333333333333333}, 'Hold': {'Bear': 0.3333333333333333, 'Bull': 0.3333333333333333, 'Flat': 0.3333333333333333}}}\n",
      "Iteration 1:\n",
      "State: Bear, Optimal Action: Buy, Value: 1.6666666666666665\n",
      "State: Bull, Optimal Action: Sell, Value: 3.7777777777777772\n",
      "State: Flat, Optimal Action: Buy, Value: 3.1185185185185187\n",
      "Iteration 2:\n",
      "State: Bear, Optimal Action: Buy, Value: 3.950123456790123\n",
      "State: Bull, Optimal Action: Sell, Value: 6.225711934156378\n",
      "State: Flat, Optimal Action: Buy, Value: 5.211827709190672\n",
      "Iteration 3:\n",
      "State: Bear, Optimal Action: Buy, Value: 5.770043493369913\n",
      "State: Bull, Optimal Action: Sell, Value: 7.922022169791191\n",
      "State: Flat, Optimal Action: Buy, Value: 6.707704899293807\n",
      "Iteration 4:\n",
      "State: Bear, Optimal Action: Buy, Value: 7.10660548332131\n",
      "State: Bull, Optimal Action: Sell, Value: 9.129688680641683\n",
      "State: Flat, Optimal Action: Buy, Value: 7.78506641686848\n",
      "Iteration 5:\n",
      "State: Bear, Optimal Action: Buy, Value: 8.07236282155506\n",
      "State: Bull, Optimal Action: Sell, Value: 9.996564778417392\n",
      "State: Flat, Optimal Action: Buy, Value: 8.561065071157582\n",
      "Iteration 6:\n",
      "State: Bear, Optimal Action: Buy, Value: 8.767998045634677\n",
      "State: Bull, Optimal Action: Sell, Value: 10.620167438722573\n",
      "State: Flat, Optimal Action: Buy, Value: 9.119794814803956\n",
      "Iteration 7:\n",
      "State: Bear, Optimal Action: Buy, Value: 9.268789413109655\n",
      "State: Bull, Optimal Action: Sell, Value: 11.069000444436316\n",
      "State: Flat, Optimal Action: Buy, Value: 9.522022579293314\n",
      "Iteration 8:\n",
      "State: Bear, Optimal Action: Buy, Value: 9.629283316490476\n",
      "State: Bull, Optimal Action: Sell, Value: 11.39208169072536\n",
      "State: Flat, Optimal Action: Buy, Value: 9.811570023069107\n",
      "Iteration 9:\n",
      "State: Bear, Optimal Action: Buy, Value: 9.888782674742652\n",
      "State: Bull, Optimal Action: Sell, Value: 11.624649170276566\n",
      "State: Flat, Optimal Action: Buy, Value: 10.020000498156884\n",
      "Iteration 10:\n",
      "State: Bear, Optimal Action: Sell, Value: 10.075581958180294\n",
      "State: Bull, Optimal Action: Sell, Value: 11.792061767097\n",
      "State: Flat, Optimal Action: Buy, Value: 10.170038459582447\n",
      "Iteration 11:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.210048582629264\n",
      "State: Bull, Optimal Action: Sell, Value: 11.912573015815656\n",
      "State: Flat, Optimal Action: Buy, Value: 10.278042682140631\n",
      "Iteration 12:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.306843808156147\n",
      "State: Bull, Optimal Action: Sell, Value: 11.999322534963316\n",
      "State: Flat, Optimal Action: Buy, Value: 10.355789073402692\n",
      "Iteration 13:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.376521444405908\n",
      "State: Bull, Optimal Action: Sell, Value: 12.06176881407251\n",
      "State: Flat, Optimal Action: Buy, Value: 10.411754488501629\n",
      "Iteration 14:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.42667859919468\n",
      "State: Bull, Optimal Action: Sell, Value: 12.106720507138352\n",
      "State: Flat, Optimal Action: Buy, Value: 10.452040958622577\n",
      "Iteration 15:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.462784017321496\n",
      "State: Bull, Optimal Action: Sell, Value: 12.139078795488647\n",
      "State: Flat, Optimal Action: Buy, Value: 10.48104100571539\n",
      "Iteration 16:\n",
      "State: Bear, Optimal Action: Sell, Value: 10.488774351606809\n",
      "State: Bull, Optimal Action: Sell, Value: 12.162371774082892\n",
      "State: Flat, Optimal Action: Buy, Value: 10.501916568374691\n",
      "Iteration 17:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.507483385083837\n",
      "State: Bull, Optimal Action: Sell, Value: 12.179139127344378\n",
      "State: Flat, Optimal Action: Buy, Value: 10.516943754880774\n",
      "Iteration 18:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.520951004615728\n",
      "State: Bull, Optimal Action: Sell, Value: 12.1912090364909\n",
      "State: Flat, Optimal Action: Buy, Value: 10.527761012263307\n",
      "Iteration 19:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.530645614231982\n",
      "State: Bull, Optimal Action: Sell, Value: 12.199897510129652\n",
      "State: Flat, Optimal Action: Buy, Value: 10.535547769766652\n",
      "Iteration 20:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.537624238434208\n",
      "State: Bull, Optimal Action: Sell, Value: 12.206151871554802\n",
      "State: Flat, Optimal Action: Buy, Value: 10.54115303460151\n",
      "Iteration 21:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.542647771890806\n",
      "State: Bull, Optimal Action: Sell, Value: 12.210654047479231\n",
      "State: Flat, Optimal Action: Buy, Value: 10.54518796105908\n",
      "Iteration 22:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.546263941447766\n",
      "State: Bull, Optimal Action: Sell, Value: 12.213894919996287\n",
      "State: Flat, Optimal Action: Buy, Value: 10.548092486000836\n",
      "Iteration 23:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.548867025985304\n",
      "State: Bull, Optimal Action: Sell, Value: 12.216227848528646\n",
      "State: Flat, Optimal Action: Buy, Value: 10.550183296137277\n",
      "Iteration 24:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.550740845506994\n",
      "State: Bull, Optimal Action: Sell, Value: 12.217907197379443\n",
      "State: Flat, Optimal Action: Buy, Value: 10.551688357072988\n",
      "Iteration 25:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.552089706655845\n",
      "State: Bull, Optimal Action: Sell, Value: 12.219116069628875\n",
      "State: Flat, Optimal Action: Buy, Value: 10.552771768895388\n",
      "Iteration 26:\n",
      "State: Bear, Optimal Action: Sell, Value: 10.553060678714695\n",
      "State: Bull, Optimal Action: Sell, Value: 12.219986271263721\n",
      "State: Flat, Optimal Action: Buy, Value: 10.553551658366349\n",
      "Iteration 27:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.553759628891939\n",
      "State: Bull, Optimal Action: Sell, Value: 12.220612682272536\n",
      "State: Flat, Optimal Action: Buy, Value: 10.554113058541553\n",
      "Iteration 28:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.554262765254942\n",
      "State: Bull, Optimal Action: Sell, Value: 12.221063601618408\n",
      "State: Flat, Optimal Action: Buy, Value: 10.55451718011064\n",
      "Iteration 29:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.554624945862397\n",
      "State: Bull, Optimal Action: Sell, Value: 12.221388194024385\n",
      "State: Flat, Optimal Action: Buy, Value: 10.554808085332645\n",
      "Iteration 30:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.554885660058513\n",
      "State: Bull, Optimal Action: Sell, Value: 12.221621850510811\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555017492240525\n",
      "Iteration 31:\n",
      "State: Bear, Optimal Action: Sell, Value: 10.555073334082627\n",
      "State: Bull, Optimal Action: Sell, Value: 12.221790047155723\n",
      "State: Flat, Optimal Action: Buy, Value: 10.5551682329277\n",
      "Iteration 32:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555208430444281\n",
      "State: Bull, Optimal Action: Sell, Value: 12.221911122807388\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555276742981166\n",
      "Iteration 33:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555305678995424\n",
      "State: Bull, Optimal Action: Sell, Value: 12.22199827860906\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555354853489504\n",
      "Iteration 34:\n",
      "State: Bear, Optimal Action: Sell, Value: 10.555375682958397\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222061017348523\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555411081012378\n",
      "Iteration 35:\n",
      "State: Bear, Optimal Action: Sell, Value: 10.555426075018481\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222106179567835\n",
      "State: Flat, Optimal Action: Buy, Value: 10.55545155615965\n",
      "Iteration 36:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555462349532256\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222138689402597\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555480692025201\n",
      "Iteration 37:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555488461589349\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222162091471237\n",
      "State: Flat, Optimal Action: Buy, Value: 10.55550166535621\n",
      "Iteration 38:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555507258244479\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222178937352513\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555516762920854\n",
      "Iteration 39:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555520788938093\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222191063789722\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555527630839645\n",
      "Iteration 40:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555530528951323\n",
      "State: Bull, Optimal Action: Sell, Value: 12.22219979295485\n",
      "State: Flat, Optimal Action: Buy, Value: 10.55553545406555\n",
      "Iteration 41:\n",
      "State: Bear, Optimal Action: Sell, Value: 10.555537540259126\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222206076607872\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555541085582012\n",
      "Iteration 42:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555542587319735\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222210599869232\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555545139405593\n",
      "Iteration 43:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555546220425216\n",
      "State: Bull, Optimal Action: Sell, Value: 12.22221385592001\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555548057533553\n",
      "Iteration 44:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555548835701007\n",
      "State: Bull, Optimal Action: Sell, Value: 12.22221619977455\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555550158135762\n",
      "Iteration 45:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555550718296352\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222217886988446\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555551670245482\n",
      "Iteration 46:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555552073474741\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222219101522311\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555552758731341\n",
      "Iteration 47:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555553048994238\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222219975799437\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555553542273337\n",
      "Optimal Policy:\n",
      "State: Bear, Optimal Action: Buy\n",
      "State: Bull, Optimal Action: Sell\n",
      "State: Flat, Optimal Action: Buy\n",
      "{'Bear': 10.555553048994238, 'Bull': 12.222219975799437, 'Flat': 10.555553542273337}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Define states and actions\n",
    "states = ['Bear', 'Bull', 'Flat']\n",
    "actions = ['Buy', 'Sell', 'Hold']\n",
    "\n",
    "\n",
    "\n",
    "#Define rewards for each state action pair\n",
    "rewards = {\n",
    "    'Bear': {\n",
    "        'Buy': {'Bear': -10, 'Bull': 10, 'Flat': 5},\n",
    "        'Sell': {'Bear': 10, 'Bull': -10, 'Flat': 5},\n",
    "        'Hold': {'Bear': -10, 'Bull': +10, 'Flat': 5}\n",
    "    },\n",
    "    'Bull': {\n",
    "        'Buy': {'Bear': -15, 'Bull': +10, 'Flat': -5},\n",
    "        'Sell': {'Bear': 15, 'Bull': -10, 'Flat': 5},\n",
    "        'Hold': {'Bear': -15, 'Bull': +15, 'Flat': -5}\n",
    "    },\n",
    "    'Flat': {\n",
    "        'Buy': {'Bear': -10, 'Bull': +15, 'Flat': 0},\n",
    "        'Sell': {'Bear': 15, 'Bull': -15, 'Flat': 0},\n",
    "        'Hold': {'Bear': -15, 'Bull': 10, 'Flat': 0}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Considering Uniform transition probability \n",
    "\n",
    "transition_probabilities = {\n",
    "    state: {\n",
    "        action: {next_state: 1/len(states) for next_state in states}\n",
    "        for action in actions\n",
    "    }\n",
    "    for state in states\n",
    "}\n",
    "\n",
    "print(transition_probabilities)\n",
    "V = {state: 0 for state in states}\n",
    "\n",
    "gamma = 0.8\n",
    "\n",
    "tolerance = 1e-6\n",
    "\n",
    "iteration = 0\n",
    "while True:\n",
    "    iteration += 1\n",
    "    delta = 0\n",
    "    print(f\"Iteration {iteration}:\")\n",
    "    for state in states:\n",
    "        old_value = V[state]\n",
    "        max_value = float('-inf')\n",
    "        max_action = None\n",
    "        #Using the Bellmans equation\n",
    "        for action in actions:\n",
    "            action_value = sum(transition_probabilities[state][action][next_state] *\n",
    "                               (rewards[state][action][next_state] + gamma * V[next_state])\n",
    "                               for next_state in states)\n",
    "            if action_value > max_value:\n",
    "                max_value = action_value\n",
    "                max_action = action\n",
    "        V[state] = max_value\n",
    "        delta = max(delta, abs(old_value - V[state]))\n",
    "        print(f\"State: {state}, Optimal Action: {max_action}, Value: {V[state]}\")\n",
    "    if delta < tolerance:\n",
    "        break\n",
    "\n",
    "# Derive optimal policy\n",
    "optimal_policy = {}\n",
    "for state in states:\n",
    "    max_action = None\n",
    "    max_action_value = float('-inf')\n",
    "    for action in actions:\n",
    "        action_value = sum(transition_probabilities[state][action][next_state] *\n",
    "                           (rewards[state][action][next_state] + gamma * V[next_state])\n",
    "                           for next_state in states)\n",
    "        if action_value > max_action_value:\n",
    "            max_action = action\n",
    "            max_action_value = action_value\n",
    "    optimal_policy[state] = max_action\n",
    "\n",
    "print(\"Optimal Policy:\")\n",
    "for state, action in optimal_policy.items():\n",
    "    print(f\"State: {state}, Optimal Action: {action}\")\n",
    "    \n",
    "print(V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f4fb42-5719-48e7-9f61-fcd6924023d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the states, actions, and next states\n",
    "states = [-1, 0, 1]\n",
    "actions = [-1, 0, 1]\n",
    "next_states = [-1, 0, 1]\n",
    "\n",
    "# Initialize the transition probability matrix\n",
    "transition_probabilities = np.zeros((len(states), len(actions), len(next_states)))\n",
    "\n",
    "# Iterate over the transition counts to calculate probabilities\n",
    "for i, state in enumerate(states):\n",
    "    for j, action in enumerate(actions):\n",
    "        total_transitions = sum(transition_counts[(state, action)].values())\n",
    "        for k, next_state in enumerate(next_states):\n",
    "            transition_count = transition_counts[(state, action)].get(next_state, 0)\n",
    "            if total_transitions != 0:\n",
    "                transition_probabilities[i, j, k] = transition_count / total_transitions\n",
    "\n",
    "# Print the transition probability matrix\n",
    "print(\"Transition Probability Matrix:\")\n",
    "print(transition_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a549c66-4947-41af-bb2b-d79196945702",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "State: Bear, Optimal Action: Buy, Value: 1.6666666666666665\n",
      "State: Bull, Optimal Action: Sell, Value: 3.7777777777777772\n",
      "State: Flat, Optimal Action: Buy, Value: 3.1185185185185187\n",
      "Iteration 2:\n",
      "State: Bear, Optimal Action: Buy, Value: 3.950123456790123\n",
      "State: Bull, Optimal Action: Sell, Value: 6.225711934156378\n",
      "State: Flat, Optimal Action: Buy, Value: 5.211827709190672\n",
      "Iteration 3:\n",
      "State: Bear, Optimal Action: Buy, Value: 5.770043493369913\n",
      "State: Bull, Optimal Action: Sell, Value: 7.922022169791191\n",
      "State: Flat, Optimal Action: Buy, Value: 6.707704899293807\n",
      "Iteration 4:\n",
      "State: Bear, Optimal Action: Buy, Value: 7.10660548332131\n",
      "State: Bull, Optimal Action: Sell, Value: 9.129688680641683\n",
      "State: Flat, Optimal Action: Buy, Value: 7.78506641686848\n",
      "Iteration 5:\n",
      "State: Bear, Optimal Action: Buy, Value: 8.07236282155506\n",
      "State: Bull, Optimal Action: Sell, Value: 9.996564778417392\n",
      "State: Flat, Optimal Action: Buy, Value: 8.561065071157582\n",
      "Iteration 6:\n",
      "State: Bear, Optimal Action: Buy, Value: 8.767998045634677\n",
      "State: Bull, Optimal Action: Sell, Value: 10.620167438722573\n",
      "State: Flat, Optimal Action: Buy, Value: 9.119794814803956\n",
      "Iteration 7:\n",
      "State: Bear, Optimal Action: Buy, Value: 9.268789413109655\n",
      "State: Bull, Optimal Action: Sell, Value: 11.069000444436316\n",
      "State: Flat, Optimal Action: Buy, Value: 9.522022579293314\n",
      "Iteration 8:\n",
      "State: Bear, Optimal Action: Buy, Value: 9.629283316490476\n",
      "State: Bull, Optimal Action: Sell, Value: 11.39208169072536\n",
      "State: Flat, Optimal Action: Buy, Value: 9.811570023069107\n",
      "Iteration 9:\n",
      "State: Bear, Optimal Action: Buy, Value: 9.888782674742652\n",
      "State: Bull, Optimal Action: Sell, Value: 11.624649170276566\n",
      "State: Flat, Optimal Action: Buy, Value: 10.020000498156884\n",
      "Iteration 10:\n",
      "State: Bear, Optimal Action: Sell, Value: 10.075581958180294\n",
      "State: Bull, Optimal Action: Sell, Value: 11.792061767097\n",
      "State: Flat, Optimal Action: Buy, Value: 10.170038459582447\n",
      "Iteration 11:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.210048582629264\n",
      "State: Bull, Optimal Action: Sell, Value: 11.912573015815656\n",
      "State: Flat, Optimal Action: Buy, Value: 10.278042682140631\n",
      "Iteration 12:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.306843808156147\n",
      "State: Bull, Optimal Action: Sell, Value: 11.999322534963316\n",
      "State: Flat, Optimal Action: Buy, Value: 10.355789073402692\n",
      "Iteration 13:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.376521444405908\n",
      "State: Bull, Optimal Action: Sell, Value: 12.06176881407251\n",
      "State: Flat, Optimal Action: Buy, Value: 10.411754488501629\n",
      "Iteration 14:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.42667859919468\n",
      "State: Bull, Optimal Action: Sell, Value: 12.106720507138352\n",
      "State: Flat, Optimal Action: Buy, Value: 10.452040958622577\n",
      "Iteration 15:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.462784017321496\n",
      "State: Bull, Optimal Action: Sell, Value: 12.139078795488647\n",
      "State: Flat, Optimal Action: Buy, Value: 10.48104100571539\n",
      "Iteration 16:\n",
      "State: Bear, Optimal Action: Sell, Value: 10.488774351606809\n",
      "State: Bull, Optimal Action: Sell, Value: 12.162371774082892\n",
      "State: Flat, Optimal Action: Buy, Value: 10.501916568374691\n",
      "Iteration 17:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.507483385083837\n",
      "State: Bull, Optimal Action: Sell, Value: 12.179139127344378\n",
      "State: Flat, Optimal Action: Buy, Value: 10.516943754880774\n",
      "Iteration 18:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.520951004615728\n",
      "State: Bull, Optimal Action: Sell, Value: 12.1912090364909\n",
      "State: Flat, Optimal Action: Buy, Value: 10.527761012263307\n",
      "Iteration 19:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.530645614231982\n",
      "State: Bull, Optimal Action: Sell, Value: 12.199897510129652\n",
      "State: Flat, Optimal Action: Buy, Value: 10.535547769766652\n",
      "Iteration 20:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.537624238434208\n",
      "State: Bull, Optimal Action: Sell, Value: 12.206151871554802\n",
      "State: Flat, Optimal Action: Buy, Value: 10.54115303460151\n",
      "Iteration 21:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.542647771890806\n",
      "State: Bull, Optimal Action: Sell, Value: 12.210654047479231\n",
      "State: Flat, Optimal Action: Buy, Value: 10.54518796105908\n",
      "Iteration 22:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.546263941447766\n",
      "State: Bull, Optimal Action: Sell, Value: 12.213894919996287\n",
      "State: Flat, Optimal Action: Buy, Value: 10.548092486000836\n",
      "Iteration 23:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.548867025985304\n",
      "State: Bull, Optimal Action: Sell, Value: 12.216227848528646\n",
      "State: Flat, Optimal Action: Buy, Value: 10.550183296137277\n",
      "Iteration 24:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.550740845506994\n",
      "State: Bull, Optimal Action: Sell, Value: 12.217907197379443\n",
      "State: Flat, Optimal Action: Buy, Value: 10.551688357072988\n",
      "Iteration 25:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.552089706655845\n",
      "State: Bull, Optimal Action: Sell, Value: 12.219116069628875\n",
      "State: Flat, Optimal Action: Buy, Value: 10.552771768895388\n",
      "Iteration 26:\n",
      "State: Bear, Optimal Action: Sell, Value: 10.553060678714695\n",
      "State: Bull, Optimal Action: Sell, Value: 12.219986271263721\n",
      "State: Flat, Optimal Action: Buy, Value: 10.553551658366349\n",
      "Iteration 27:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.553759628891939\n",
      "State: Bull, Optimal Action: Sell, Value: 12.220612682272536\n",
      "State: Flat, Optimal Action: Buy, Value: 10.554113058541553\n",
      "Iteration 28:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.554262765254942\n",
      "State: Bull, Optimal Action: Sell, Value: 12.221063601618408\n",
      "State: Flat, Optimal Action: Buy, Value: 10.55451718011064\n",
      "Iteration 29:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.554624945862397\n",
      "State: Bull, Optimal Action: Sell, Value: 12.221388194024385\n",
      "State: Flat, Optimal Action: Buy, Value: 10.554808085332645\n",
      "Iteration 30:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.554885660058513\n",
      "State: Bull, Optimal Action: Sell, Value: 12.221621850510811\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555017492240525\n",
      "Iteration 31:\n",
      "State: Bear, Optimal Action: Sell, Value: 10.555073334082627\n",
      "State: Bull, Optimal Action: Sell, Value: 12.221790047155723\n",
      "State: Flat, Optimal Action: Buy, Value: 10.5551682329277\n",
      "Iteration 32:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555208430444281\n",
      "State: Bull, Optimal Action: Sell, Value: 12.221911122807388\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555276742981166\n",
      "Iteration 33:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555305678995424\n",
      "State: Bull, Optimal Action: Sell, Value: 12.22199827860906\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555354853489504\n",
      "Iteration 34:\n",
      "State: Bear, Optimal Action: Sell, Value: 10.555375682958397\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222061017348523\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555411081012378\n",
      "Iteration 35:\n",
      "State: Bear, Optimal Action: Sell, Value: 10.555426075018481\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222106179567835\n",
      "State: Flat, Optimal Action: Buy, Value: 10.55545155615965\n",
      "Iteration 36:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555462349532256\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222138689402597\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555480692025201\n",
      "Iteration 37:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555488461589349\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222162091471237\n",
      "State: Flat, Optimal Action: Buy, Value: 10.55550166535621\n",
      "Iteration 38:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555507258244479\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222178937352513\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555516762920854\n",
      "Iteration 39:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555520788938093\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222191063789722\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555527630839645\n",
      "Iteration 40:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555530528951323\n",
      "State: Bull, Optimal Action: Sell, Value: 12.22219979295485\n",
      "State: Flat, Optimal Action: Buy, Value: 10.55553545406555\n",
      "Iteration 41:\n",
      "State: Bear, Optimal Action: Sell, Value: 10.555537540259126\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222206076607872\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555541085582012\n",
      "Iteration 42:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555542587319735\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222210599869232\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555545139405593\n",
      "Iteration 43:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555546220425216\n",
      "State: Bull, Optimal Action: Sell, Value: 12.22221385592001\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555548057533553\n",
      "Iteration 44:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555548835701007\n",
      "State: Bull, Optimal Action: Sell, Value: 12.22221619977455\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555550158135762\n",
      "Iteration 45:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555550718296352\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222217886988446\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555551670245482\n",
      "Iteration 46:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555552073474741\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222219101522311\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555552758731341\n",
      "Iteration 47:\n",
      "State: Bear, Optimal Action: Buy, Value: 10.555553048994238\n",
      "State: Bull, Optimal Action: Sell, Value: 12.222219975799437\n",
      "State: Flat, Optimal Action: Buy, Value: 10.555553542273337\n",
      "Optimal Policy:\n",
      "State: Bear, Optimal Action: Buy\n",
      "State: Bull, Optimal Action: Sell\n",
      "State: Flat, Optimal Action: Buy\n",
      "{'Bear': 10.555553048994238, 'Bull': 12.222219975799437, 'Flat': 10.555553542273337}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "states = ['Bear', 'Bull', 'Flat']\n",
    "actions = ['Buy', 'Sell', 'Hold']\n",
    "\n",
    "rewards = {\n",
    "    'Bear': {\n",
    "        'Buy': {'Bear': -10, 'Bull': 10, 'Flat': 5},\n",
    "        'Sell': {'Bear': 10, 'Bull': -10, 'Flat': 5},\n",
    "        'Hold': {'Bear': -10, 'Bull': +10, 'Flat': 5}\n",
    "    },\n",
    "    'Bull': {\n",
    "        'Buy': {'Bear': -15, 'Bull': +10, 'Flat': -5},\n",
    "        'Sell': {'Bear': 15, 'Bull': -10, 'Flat': 5},\n",
    "        'Hold': {'Bear': -15, 'Bull': +15, 'Flat': -5}\n",
    "    },\n",
    "    'Flat': {\n",
    "        'Buy': {'Bear': -10, 'Bull': +15, 'Flat': 0},\n",
    "        'Sell': {'Bear': 15, 'Bull': -15, 'Flat': 0},\n",
    "        'Hold': {'Bear': -15, 'Bull': 10, 'Flat': 0}\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "transition_probabilities = {\n",
    "    state: {\n",
    "        action: {next_state: 1/len(states) for next_state in states}\n",
    "        for action in actions\n",
    "    }\n",
    "    for state in states\n",
    "}\n",
    "\n",
    "# Initialize value function\n",
    "V = {state: 0 for state in states}\n",
    "\n",
    "# Discount factor\n",
    "gamma = 0.8\n",
    "\n",
    "tolerance = 1e-6\n",
    "\n",
    "# Perform value iteration until convergence\n",
    "iteration = 0\n",
    "while True:\n",
    "    iteration += 1\n",
    "    delta = 0\n",
    "    print(f\"Iteration {iteration}:\")\n",
    "    for state in states:\n",
    "        old_value = V[state]\n",
    "        max_value = float('-inf')\n",
    "        max_action = None\n",
    "        # Using the Bellman equation\n",
    "        for action in actions:\n",
    "            action_value = sum(transition_probabilities[state][action][next_state] *\n",
    "                               (rewards[state][action][next_state] + gamma * V[next_state])\n",
    "                               for next_state in states)\n",
    "            if action_value > max_value:\n",
    "                max_value = action_value\n",
    "                max_action = action\n",
    "        V[state] = max_value\n",
    "        delta = max(delta, abs(old_value - V[state]))\n",
    "        print(f\"State: {state}, Optimal Action: {max_action}, Value: {V[state]}\")\n",
    "    if delta < tolerance:\n",
    "        break\n",
    "\n",
    "# Derive optimal policy\n",
    "optimal_policy = {}\n",
    "for state in states:\n",
    "    max_action = None\n",
    "    max_action_value = float('-inf')\n",
    "    for action in actions:\n",
    "        action_value = sum(transition_probabilities[state][action][next_state] *\n",
    "                           (rewards[state][action][next_state] + gamma * V[next_state])\n",
    "                           for next_state in states)\n",
    "        if action_value > max_action_value:\n",
    "            max_action = action\n",
    "            max_action_value = action_value\n",
    "    optimal_policy[state] = max_action\n",
    "\n",
    "print(\"Optimal Policy:\")\n",
    "for state, action in optimal_policy.items():\n",
    "    print(f\"State: {state}, Optimal Action: {action}\")\n",
    "    \n",
    "print(V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4128d507-0056-456c-afba-fefaa132ab0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Actions:\n",
      "State: Bear, Optimal Action: Buy\n",
      "State: Bull, Optimal Action: Hold\n",
      "State: Flat, Optimal Action: Buy\n"
     ]
    }
   ],
   "source": [
    "# Define states and actions\n",
    "states = ['Bear', 'Bull', 'Flat']\n",
    "actions = ['Buy', 'Sell', 'Hold']\n",
    "\n",
    "# Define rewards for each state-action pair\n",
    "rewards = {\n",
    "    'Bear': {\n",
    "        'Buy': {'Bear': -10, 'Bull': 10, 'Flat': 5},\n",
    "        'Sell': {'Bear': 10, 'Bull': -10, 'Flat': 5},\n",
    "        'Hold': {'Bear': -10, 'Bull': +10, 'Flat': 5}\n",
    "    },\n",
    "    'Bull': {\n",
    "        'Buy': {'Bear': -15, 'Bull': +10, 'Flat': -5},\n",
    "        'Sell': {'Bear': 15, 'Bull': -10, 'Flat': 5},\n",
    "        'Hold': {'Bear': -15, 'Bull': +15, 'Flat': -5}\n",
    "    },\n",
    "    'Flat': {\n",
    "        'Buy': {'Bear': -10, 'Bull': +15, 'Flat': 0},\n",
    "        'Sell': {'Bear': 15, 'Bull': -15, 'Flat': 0},\n",
    "        'Hold': {'Bear': -15, 'Bull': 10, 'Flat': 0}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define transition probabilities (assuming uniform distribution)\n",
    "transition_probabilities = {\n",
    "    'Bear': {\n",
    "        'Buy': {'Bear': 0.1, 'Bull': 0.7, 'Flat': 0.2},\n",
    "        'Sell': {'Bear': 0.6, 'Bull': 0.3, 'Flat': 0.1},\n",
    "        'Hold': {'Bear': 0.4, 'Bull': 0.4, 'Flat': 0.2}\n",
    "    },\n",
    "    'Bull': {\n",
    "        'Buy': {'Bear': 0.3, 'Bull': 0.4, 'Flat': 0.3},\n",
    "        'Sell': {'Bear': 0.2, 'Bull': 0.5, 'Flat': 0.3},\n",
    "        'Hold': {'Bear': 0.1, 'Bull': 0.6, 'Flat': 0.3}\n",
    "    },\n",
    "    'Flat': {\n",
    "        'Buy': {'Bear': 0.2, 'Bull': 0.6, 'Flat': 0.2},\n",
    "        'Sell': {'Bear': 0.3, 'Bull': 0.4, 'Flat': 0.3},\n",
    "        'Hold': {'Bear': 0.3, 'Bull': 0.3, 'Flat': 0.4}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Discount factor\n",
    "gamma = 0.8\n",
    "\n",
    "# Convergence threshold\n",
    "tolerance = 1e-6\n",
    "\n",
    "# Initialize value function and optimal actions\n",
    "V = {state: 0 for state in states}\n",
    "optimal_actions = {state: None for state in states}\n",
    "\n",
    "# Perform value iteration until convergence\n",
    "while True:\n",
    "    delta = 0\n",
    "    for state in states:\n",
    "        old_value = V[state]\n",
    "        max_value = float('-inf')\n",
    "        max_action = None\n",
    "        # Calculate the value for each action and choose the one with the maximum value\n",
    "        for action in actions:\n",
    "            action_value = sum(transition_probabilities[state][action][next_state] *\n",
    "                               (rewards[state][action][next_state] + gamma * V[next_state])\n",
    "                               for next_state in states)\n",
    "            if action_value > max_value:\n",
    "                max_value = action_value\n",
    "                max_action = action\n",
    "        V[state] = max_value\n",
    "        optimal_actions[state] = max_action\n",
    "        delta = max(delta, abs(old_value - V[state]))\n",
    "    if delta < tolerance:\n",
    "        break\n",
    "\n",
    "# Print the optimal actions for each state\n",
    "print(\"Optimal Actions:\")\n",
    "for state, action in optimal_actions.items():\n",
    "    print(f\"State: {state}, Optimal Action: {action}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "158abf4b-1cee-4ffd-ac7f-d73336a4386b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Probability Dictionary:\n",
      "{'Bear': {'Buy': {'Bear': 0.0, 'Bull': 0.0, 'Flat': 0.0}, 'Sell': {'Bear': 0.4137931, 'Bull': 0.34482759, 'Flat': 0.24137931}, 'Hold': {'Bear': 0.0, 'Bull': 0.0, 'Flat': 0.0}}, 'Bull': {'Buy': {'Bear': 1.0, 'Bull': 0.0, 'Flat': 0.0}, 'Sell': {'Bear': 0.0, 'Bull': 1.0, 'Flat': 0.0}, 'Hold': {'Bear': 0.0, 'Bull': 0.0, 'Flat': 1.0}}, 'Flat': {'Buy': {'Bear': 0.0, 'Bull': 0.0, 'Flat': 0.0}, 'Sell': {'Bear': 0.28169014, 'Bull': 0.47887324, 'Flat': 0.23943662}, 'Hold': {'Bear': 0.0, 'Bull': 0.0, 'Flat': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "# Define the provided transition probability array\n",
    "transition_probabilities = np.array([[[0.0, 0.0, 0.0],\n",
    "                                      [0.4137931, 0.34482759, 0.24137931],\n",
    "                                      [0.0, 0.0, 0.0]],\n",
    "\n",
    "                                     [[1.0, 0.0, 0.0],\n",
    "                                      [0.0, 1.0, 0.0],\n",
    "                                      [0.0, 0.0, 1.0]],\n",
    "\n",
    "                                     [[0.0, 0.0, 0.0],\n",
    "                                      [0.28169014, 0.47887324, 0.23943662],\n",
    "                                      [0.0, 0.0, 0.0]]])\n",
    "\n",
    "# Define the states, actions, and next states\n",
    "states = ['Bear', 'Bull', 'Flat']\n",
    "actions = ['Buy', 'Sell', 'Hold']\n",
    "next_states=['Bear', 'Bull', 'Flat']\n",
    "\n",
    "# Initialize an empty dictionary to store the transition probabilities\n",
    "transition_prob_dict = {}\n",
    "\n",
    "# Iterate over the states, actions, and next states to build the dictionary\n",
    "for i, state in enumerate(states):\n",
    "    state_dict = {}\n",
    "    for j, action in enumerate(actions):\n",
    "        action_dict = {}\n",
    "        for k, next_state in enumerate(next_states):\n",
    "            action_dict[next_state] = transition_probabilities[i, j, k]\n",
    "        state_dict[action] = action_dict\n",
    "    transition_prob_dict[state] = state_dict\n",
    "\n",
    "# Print the transition probability dictionary\n",
    "print(\"Transition Probability Dictionary:\")\n",
    "print(transition_prob_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ffcb05e-fd27-4920-a7d4-6a55c6b623d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Actions:\n",
      "State: Bear, Optimal Action: Sell\n",
      "State: Bull, Optimal Action: Hold\n",
      "State: Flat, Optimal Action: Buy\n"
     ]
    }
   ],
   "source": [
    "# Define states and actions\n",
    "states = ['Bear', 'Bull', 'Flat']\n",
    "actions = ['Buy', 'Sell', 'Hold']\n",
    "\n",
    "# Define rewards for each state-action pair\n",
    "rewards = {\n",
    "    'Bear': {\n",
    "        'Buy': {'Bear': -10, 'Bull': 10, 'Flat': 5},\n",
    "        'Sell': {'Bear': 10, 'Bull': -10, 'Flat': 5},\n",
    "        'Hold': {'Bear': -10, 'Bull': +10, 'Flat': 5}\n",
    "    },\n",
    "    'Bull': {\n",
    "        'Buy': {'Bear': -15, 'Bull': +10, 'Flat': -5},\n",
    "        'Sell': {'Bear': 15, 'Bull': -10, 'Flat': 5},\n",
    "        'Hold': {'Bear': -15, 'Bull': +15, 'Flat': -5}\n",
    "    },\n",
    "    'Flat': {\n",
    "        'Buy': {'Bear': -10, 'Bull': +15, 'Flat': 0},\n",
    "        'Sell': {'Bear': 15, 'Bull': -15, 'Flat': 0},\n",
    "        'Hold': {'Bear': -15, 'Bull': 10, 'Flat': 0}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define transition probabilities (assuming uniform distribution)\n",
    "transition_probabilities = transition_prob_dict\n",
    "\n",
    "# Discount factor\n",
    "gamma = 0.8\n",
    "\n",
    "# Convergence threshold\n",
    "tolerance = 1e-6\n",
    "\n",
    "# Initialize value function and optimal actions\n",
    "V = {state: 0 for state in states}\n",
    "optimal_actions = {state: None for state in states}\n",
    "\n",
    "# Perform value iteration until convergence\n",
    "while True:\n",
    "    delta = 0\n",
    "    for state in states:\n",
    "        old_value = V[state]\n",
    "        max_value = float('-inf')\n",
    "        max_action = None\n",
    "        # Calculate the value for each action and choose the one with the maximum value\n",
    "        for action in actions:\n",
    "            action_value = sum(transition_probabilities[state][action][next_state] *\n",
    "                               (rewards[state][action][next_state] + gamma * V[next_state])\n",
    "                               for next_state in states)\n",
    "            if action_value > max_value:\n",
    "                max_value = action_value\n",
    "                max_action = action\n",
    "        V[state] = max_value\n",
    "        optimal_actions[state] = max_action\n",
    "        delta = max(delta, abs(old_value - V[state]))\n",
    "    if delta < tolerance:\n",
    "        break\n",
    "\n",
    "# Print the optimal actions for each state\n",
    "print(\"Optimal Actions:\")\n",
    "for state, action in optimal_actions.items():\n",
    "    print(f\"State: {state}, Optimal Action: {action}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a6c08562-20e1-4376-bc16-b86a48933868",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-values:\n",
      "[[43.78779302 30.44013319  0.        ]\n",
      " [36.32075034 52.74747855  0.        ]\n",
      " [42.85606711 26.5585832   0.        ]]\n",
      "Policy:\n",
      "{'Bear': 'Buy', 'Bull': 'Sell', 'Flat': 'Buy'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the states, actions, and next states\n",
    "states = ['Bear', 'Bull', 'Flat']\n",
    "actions = ['Buy', 'Sell', 'Hold']\n",
    "num_states = len(states)\n",
    "num_actions = len(actions)\n",
    "\n",
    "# Initialize Q-table with zeros\n",
    "Q = np.zeros((num_states, num_actions))\n",
    "\n",
    "# Define rewards\n",
    "rewards = {\n",
    "    'Bear': {'Buy': 10, 'Sell': -10, 'Hold': -15},\n",
    "    'Bull': {'Buy': -10, 'Sell': 15, 'Hold': -5},\n",
    "    'Flat': {'Buy': 5, 'Sell': -5, 'Hold': 0}\n",
    "}\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.1  # Learning rate\n",
    "gamma = 0.8  # Discount factor\n",
    "epsilon = 0.1  # Epsilon-greedy parameter\n",
    "num_episodes = 1000\n",
    "\n",
    "# Q-learning algorithm\n",
    "for _ in range(num_episodes):\n",
    "    # Choose initial state randomly\n",
    "    current_state = np.random.choice(states)\n",
    "    #print(current_state,\" Current State\")\n",
    "    \n",
    "    while True:\n",
    "        # Epsilon-greedy action selection\n",
    "        if np.random.rand() < epsilon:\n",
    "            # Choose a random action\n",
    "            action = np.random.choice(actions)\n",
    "        else:\n",
    "            # Choose action with maximum Q-value for current state\n",
    "            action_idx = np.argmax(Q[states.index(current_state)])\n",
    "            action = actions[action_idx]\n",
    "        \n",
    "        # Take action and observe next state\n",
    "        # In this example, we are choosing the next state randomly, \n",
    "        # but in a real scenario, it would be determined by the environment.\n",
    "        next_state = np.random.choice(states)\n",
    "        #print(\"Next state:\", next_state)  # Debugging line\n",
    "        \n",
    "        # Get reward for the transition\n",
    "        reward = rewards[current_state][action]\n",
    "        \n",
    "        # Update Q-value using the Bellman equation\n",
    "        next_state_idx = states.index(next_state)\n",
    "        Q[states.index(current_state)][action_idx] += alpha * (reward + gamma * np.max(Q[next_state_idx]) - Q[states.index(current_state)][action_idx])\n",
    "        \n",
    "        # Move to the next state\n",
    "        current_state = next_state\n",
    "        \n",
    "        # Check if the episode is finished\n",
    "        if current_state == 'Flat':\n",
    "            break\n",
    "\n",
    "policy = {}\n",
    "for state in states:\n",
    "    action_idx = np.argmax(Q[states.index(state)])\n",
    "    policy[state] = actions[action_idx]\n",
    "\n",
    "# Print Q-values and policy\n",
    "print(\"Q-values:\")\n",
    "print(Q)\n",
    "print(\"Policy:\")\n",
    "print(policy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9fbbcb4-611a-475c-8f15-0d65c50c4f70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Indices to Buy the Stock: [6, 7, 8, 17, 19, 20, 21, 26, 30, 37, 38, 39, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 64, 67, 70, 71, 74, 78, 81, 83, 84, 85, 87, 89, 92, 97, 100, 101, 102, 104, 107, 113, 116, 119, 120, 121, 125, 126, 127, 128, 129, 131, 133, 134, 136, 137, 138, 142, 143, 144, 147, 151, 152, 154, 155, 156, 157, 162, 163, 168, 173, 190, 201, 204, 244]\n"
     ]
    }
   ],
   "source": [
    "class PortfolioOptimizer:\n",
    "    def __init__(self):\n",
    "        self.portfolio_value = 0\n",
    "        self.transition_counts = {'+1': {'+1': 0, '0': 0, '-1': 0},\n",
    "                                  '0': {'+1': 0, '0': 0, '-1': 0},\n",
    "                                  '-1': {'+1': 0, '0': 0, '-1': 0}}\n",
    "        self.current_state = None\n",
    "        self.transition_probabilities = None\n",
    "        self.buy_indices = []  # List to store indices of buy decisions\n",
    "\n",
    "    def classify_state(self, returns):\n",
    "        if returns >= 0.1:\n",
    "            return '+1'\n",
    "        elif returns > -0.1:\n",
    "            return '0'\n",
    "        else:\n",
    "            return '-1'\n",
    "\n",
    "    def update_transition_counts(self, previous_state, current_state):\n",
    "        self.transition_counts[previous_state][current_state] += 1\n",
    "        # Set transition probabilities to None to indicate they need to be recalculated\n",
    "        self.transition_probabilities = None\n",
    "\n",
    "    def calculate_transition_probabilities(self):\n",
    "        if self.transition_probabilities is None:\n",
    "            transition_probabilities = {}\n",
    "            for previous_state, transitions in self.transition_counts.items():\n",
    "                total_transitions = sum(transitions.values())\n",
    "                transition_probabilities[previous_state] = {}\n",
    "                for new_state, count in transitions.items():\n",
    "                    if total_transitions != 0:\n",
    "                        transition_probabilities[previous_state][new_state] = count / total_transitions\n",
    "                    else:\n",
    "                        transition_probabilities[previous_state][new_state] = 0\n",
    "            self.transition_probabilities = transition_probabilities\n",
    "        return self.transition_probabilities\n",
    "    \n",
    "    def make_decision(self, current_returns, day_index):\n",
    "        current_state = self.classify_state(current_returns)\n",
    "        if self.current_state is not None:\n",
    "            self.update_transition_counts(self.current_state, current_state)\n",
    "\n",
    "            # Calculate transition probabilities only when necessary\n",
    "            transition_probabilities = self.calculate_transition_probabilities()\n",
    "\n",
    "            # Find the action with the highest transition probability\n",
    "            max_probability_action = max(transition_probabilities[self.current_state], key=transition_probabilities[self.current_state].get)\n",
    "\n",
    "            # Perform the action based on the highest transition probability\n",
    "            if max_probability_action == '+1':\n",
    "                #print(\"The probability of going to state +1 is greater than other states\")\n",
    "                self.portfolio_value += 1\n",
    "                self.buy_indices.append(day_index)  # Record index of buy decision\n",
    "            elif max_probability_action == '-1':\n",
    "                #print(\"The probability of going to state -1 is greater than other states\")\n",
    "                self.portfolio_value -= 1\n",
    "            \n",
    "\n",
    "        self.current_state = current_state\n",
    "\n",
    "\n",
    "# Example usage\n",
    "portfolio_optimizer = PortfolioOptimizer()\n",
    "\n",
    "# Iterate over each day's returns and make decisions\n",
    "for i in range(1, len(prices)):\n",
    "    current_return = ((prices[i] - prices[i-1]) / prices[i-1]) * 100  # Calculate the return for the current day\n",
    "    portfolio_optimizer.make_decision(current_return, i)\n",
    "    #print(f\"Day {i}: Portfolio Value - {portfolio_optimizer.portfolio_value}\")\n",
    "\n",
    "# Print the optimal indices to buy the stock\n",
    "print(\"Optimal Indices to Buy the Stock:\", portfolio_optimizer.buy_indices)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
